{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# --- Part 0: 環境準備 ---\n",
        "# 1. 安裝 PyTorch 和對應的 torchvision, torchaudio\n",
        "\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "# 安裝 tifffile 和 imagecodecs\n",
        "!pip install tifffile imagecodecs\n",
        "# 安裝albumentations\n",
        "!pip install albumentations==1.0.3\n",
        "# 2. 安裝 Detectron2\n",
        "!pip install -U cython pyyaml==6.0\n",
        "!pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "\n",
        "# 3. Clone Detectron2\n",
        "!rm -rf detectron2_repo\n",
        "!git clone https://github.com/facebookresearch/detectron2.git detectron2_repo\n",
        "print(\"Detectron2 repo (main branch) cloned to 'detectron2_repo'\")"
      ],
      "metadata": {
        "id": "WwMpv0-1U3Mf",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_hF9Svo5DWy",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# --- 必要導入---\n",
        "import torch\n",
        "import detectron2\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.config import get_cfg, CfgNode\n",
        "from detectron2.modeling import build_model\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.evaluation import COCOEvaluator\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog, build_detection_train_loader\n",
        "from detectron2.data import detection_utils as utils\n",
        "from detectron2.structures import BoxMode\n",
        "from pycocotools import mask as mask_util\n",
        "import os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "import tifffile\n",
        "import copy\n",
        "\n",
        "# Albumentations 導入\n",
        "import albumentations as A\n",
        "\n",
        "from google.colab.patches import cv2_imshow # 如果有視覺化\n",
        "\n",
        "\n",
        "# 4. 將 PointRend 專案路徑添加到 sys.path 並導入\n",
        "import sys\n",
        "\n",
        "point_rend_path_from_clone = \"detectron2_repo/projects/PointRend\"\n",
        "if os.path.exists(point_rend_path_from_clone): # 確保路徑存在\n",
        "    if point_rend_path_from_clone not in sys.path:\n",
        "        sys.path.insert(1, point_rend_path_from_clone)\n",
        "        print(f\"Added '{point_rend_path_from_clone}' to sys.path\")\n",
        "else:\n",
        "    print(f\"WARNING: Cloned directory '{point_rend_path_from_clone}' not found. PointRend import might fail.\")\n",
        "\n",
        "POINTREND_PROJECT_AVAILABLE_AND_SETUP = False\n",
        "try:\n",
        "    import point_rend\n",
        "    print(\"Successfully imported 'point_rend' module from detectron2_repo.\")\n",
        "    POINTREND_PROJECT_AVAILABLE_AND_SETUP = True\n",
        "except ImportError:\n",
        "    try:\n",
        "        import detectron2.projects.point_rend as point_rend_pkg\n",
        "        point_rend = point_rend_pkg\n",
        "        print(\"Successfully imported 'point_rend' module from installed detectron2 package.\")\n",
        "        POINTREND_PROJECT_AVAILABLE_AND_SETUP = True\n",
        "    except ImportError as e_pip:\n",
        "        print(f\"ERROR: Failed to import 'point_rend' from both cloned repo and pip package: {e_pip}\")\n",
        "        print(\"PointRend functionalities will not be available.\")\n",
        "        print(\"Ensure Detectron2 is correctly installed and 'projects/PointRend' is accessible.\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
        "# --- 1. 掛載 Google Drive 並設定路徑 ---\n",
        "CLASS_NAMES = [\"class1\", \"class2\", \"class3\", \"class4\"]\n",
        "BASE_DIR = Path('/content/drive/MyDrive/hw3-data-release')\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 將此路徑修改為在GoogleDrive中存放資料集的位置\n",
        "BASE_DIR = Path('/content/drive/MyDrive/hw3-data-release')\n",
        "TRAIN_VAL_DIR = BASE_DIR / 'train'\n",
        "TEST_IMG_DIR = BASE_DIR / 'test'\n",
        "TEST_JSON_PATH = BASE_DIR / 'test_image_name_to_ids.json'\n",
        "\n",
        "# 定義類別名稱\n",
        "CLASS_NAMES = [\"class1\", \"class2\", \"class3\", \"class4\"]\n",
        "\n",
        "# --- 2. 資料載入與預處理函式 ---\n",
        "def get_cell_instance_dicts(image_folder_names, base_img_dir_path):\n",
        "    dataset_dicts = []\n",
        "    for img_folder_name in image_folder_names:\n",
        "        record = {}\n",
        "\n",
        "        image_file_path_str = str(base_img_dir_path / img_folder_name / \"image.tif\")\n",
        "\n",
        "        try:\n",
        "            image = tifffile.imread(image_file_path_str)\n",
        "            original_dtype = image.dtype\n",
        "\n",
        "            if image.ndim == 2:\n",
        "                image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
        "            elif image.shape[2] == 1:\n",
        "                image = cv2.cvtColor(image[:,:,0], cv2.COLOR_GRAY2RGB)\n",
        "            elif image.shape[2] == 4:\n",
        "                image = image[:,:,:3]\n",
        "            elif image.shape[2] > 3 :\n",
        "                print(f\"警告：影像 {image_file_path_str} 有 {image.shape[2]} 個通道。將取前3個通道。\")\n",
        "                image = image[:,:,:3]\n",
        "\n",
        "            if image.dtype != np.uint8:\n",
        "                max_val = np.max(image)\n",
        "                if max_val > 0:\n",
        "                    image = (image / max_val * 255).astype(np.uint8)\n",
        "                else:\n",
        "                    image = image.astype(np.uint8)\n",
        "\n",
        "            height, width = image.shape[:2]\n",
        "        except Exception as e:\n",
        "            print(f\"讀取影像 {image_file_path_str} 或轉換時發生錯誤: {e}\")\n",
        "            continue\n",
        "\n",
        "        record[\"file_name\"] = image_file_path_str\n",
        "        record[\"image_id\"] = img_folder_name\n",
        "        record[\"height\"] = height\n",
        "        record[\"width\"] = width\n",
        "\n",
        "        annotations = []\n",
        "        for class_idx, class_name in enumerate(CLASS_NAMES):\n",
        "            mask_file_path_str = str(base_img_dir_path / img_folder_name / f\"{class_name}.tif\")\n",
        "\n",
        "            if os.path.exists(mask_file_path_str):\n",
        "                try:\n",
        "\n",
        "                    instance_mask_for_class_type = tifffile.imread(mask_file_path_str)\n",
        "                except Exception as e:\n",
        "                    print(f\"讀取遮罩 {mask_file_path_str} 時發生錯誤: {e}\")\n",
        "                    continue\n",
        "\n",
        "                unique_instance_pixel_values = np.unique(instance_mask_for_class_type)\n",
        "\n",
        "                unique_instance_pixel_values = unique_instance_pixel_values[unique_instance_pixel_values != 0]\n",
        "\n",
        "                for instance_value in unique_instance_pixel_values:\n",
        "\n",
        "                    binary_instance_mask = (instance_mask_for_class_type == instance_value).astype(np.uint8)\n",
        "\n",
        "                    if np.sum(binary_instance_mask) == 0:\n",
        "                        continue\n",
        "\n",
        "\n",
        "                    ys, xs = np.where(binary_instance_mask > 0)\n",
        "                    if len(xs) == 0 or len(ys) == 0: continue\n",
        "\n",
        "                    xmin, xmax = float(np.min(xs)), float(np.max(xs))\n",
        "                    ymin, ymax = float(np.min(ys)), float(np.max(ys))\n",
        "\n",
        "\n",
        "                    rle = mask_util.encode(np.asfortranarray(binary_instance_mask))\n",
        "\n",
        "                    obj = {\n",
        "                        \"bbox\": [xmin, ymin, xmax, ymax],\n",
        "                        \"bbox_mode\": BoxMode.XYXY_ABS, # 絕對座標\n",
        "                        \"segmentation\": rle, # 使用 pycocotools RLE 格式\n",
        "                        \"category_id\": class_idx, # 0 索引的類別 ID\n",
        "                    }\n",
        "                    annotations.append(obj)\n",
        "        record[\"annotations\"] = annotations\n",
        "        dataset_dicts.append(record)\n",
        "    return dataset_dicts\n",
        "\n",
        "# --- 3. 資料集註冊 ---\n",
        "# 獲取訓練/驗證目錄中所有影像資料夾的列表\n",
        "all_image_folders = sorted([d.name for d in TRAIN_VAL_DIR.iterdir() if d.is_dir()])\n",
        "random.seed(42)\n",
        "random.shuffle(all_image_folders)\n",
        "\n",
        "# 分割資料集：總共 209 張影像用於訓練/驗證。使用約 80% 作為訓練集，20% 作為驗證集。\n",
        "num_total_train_val = len(all_image_folders)\n",
        "num_train = int(num_total_train_val * 0.8)\n",
        "train_image_ids = all_image_folders[:num_train]\n",
        "val_image_ids = all_image_folders[num_train:]\n",
        "\n",
        "print(f\"用於訓練/驗證的總影像數: {num_total_train_val}\")\n",
        "print(f\"訓練影像數: {len(train_image_ids)}\")\n",
        "print(f\"驗證影像數: {len(val_image_ids)}\")\n",
        "\n",
        "# 註冊資料集到 Detectron2\n",
        "for d_name, ids_subset in [(\"train\", train_image_ids), (\"val\", val_image_ids)]:\n",
        "    dataset_name_registered = f\"cells_{d_name}\"\n",
        "    DatasetCatalog.register(dataset_name_registered, lambda ids=ids_subset: get_cell_instance_dicts(ids, TRAIN_VAL_DIR))\n",
        "    MetadataCatalog.get(dataset_name_registered).set(thing_classes=CLASS_NAMES)\n",
        "\n",
        "#驗證資料集載入並視覺化一些樣本\n",
        "cells_metadata_train = MetadataCatalog.get(\"cells_train\")\n",
        "sample_dicts_to_visualize = get_cell_instance_dicts(train_image_ids[:2], TRAIN_VAL_DIR) # 取前兩個訓練樣本\n",
        "for d_sample in sample_dicts_to_visualize:\n",
        "    loaded_img_for_viz = tifffile.imread(d_sample[\"file_name\"])\n",
        "\n",
        "    if loaded_img_for_viz.ndim == 2: loaded_img_for_viz = cv2.cvtColor(loaded_img_for_viz, cv2.COLOR_GRAY2RGB)\n",
        "    elif loaded_img_for_viz.shape[2] == 1: loaded_img_for_viz = cv2.cvtColor(loaded_img_for_viz[:,:,0], cv2.COLOR_GRAY2RGB)\n",
        "    elif loaded_img_for_viz.shape[2] == 4: loaded_img_for_viz = loaded_img_for_viz[:,:,:3]\n",
        "    elif loaded_img_for_viz.shape[2] > 3: loaded_img_for_viz = loaded_img_for_viz[:,:,:3]\n",
        "    if loaded_img_for_viz.dtype != np.uint8:\n",
        "        max_val_viz = np.max(loaded_img_for_viz)\n",
        "        if max_val_viz > 0: loaded_img_for_viz = (loaded_img_for_viz / max_val_viz * 255).astype(np.uint8)\n",
        "        else: loaded_img_for_viz = loaded_img_for_viz.astype(np.uint8)\n",
        "\n",
        "    visualizer = Visualizer(loaded_img_for_viz[:, :, ::-1], metadata=cells_metadata_train, scale=0.7)\n",
        "    vis_output = visualizer.draw_dataset_dict(d_sample)\n",
        "    cv2_imshow(vis_output.get_image()[:, :, ::-1])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UifpMzqo5WjP",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. 模型設定 ---\n",
        "from detectron2.config import get_cfg, CfgNode\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.modeling import build_model\n",
        "import os\n",
        "\n",
        "# === PointRend 相關導入 ===\n",
        "POINTREND_PROJECT_AVAILABLE_AND_SETUP = False\n",
        "POINTREND_CONFIG_SUCCESSFULLY_APPLIED = False # 用於追蹤 PointRend 是否真的配置成功\n",
        "try:\n",
        "    import point_rend\n",
        "    print(\"Successfully imported 'point_rend' module (likely from detectron2_repo).\")\n",
        "    POINTREND_PROJECT_AVAILABLE_AND_SETUP = True\n",
        "except ImportError:\n",
        "    try:\n",
        "        import detectron2.projects.point_rend as point_rend_pkg\n",
        "        point_rend = point_rend_pkg\n",
        "        print(\"Successfully imported 'point_rend' module from installed detectron2 package.\")\n",
        "        POINTREND_PROJECT_AVAILABLE_AND_SETUP = True\n",
        "    except ImportError as e_final:\n",
        "        print(f\"ERROR: Failed to import 'point_rend' module: {e_final}\")\n",
        "        print(\"PointRend functionalities will not be available.\")\n",
        "# === PointRend 導入結束 ===\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.INPUT.MASK_FORMAT = \"bitmask\"\n",
        "MODEL_DESCRIPTION_FOR_OUTPUT = \"X101_FPN_NoPointRend_v013\"\n",
        "\n",
        "if POINTREND_PROJECT_AVAILABLE_AND_SETUP:\n",
        "    print(\"PointRend 專案可用，將調用 add_pointrend_config(cfg) 以確保配置結構存在。\")\n",
        "    point_rend.add_pointrend_config(cfg) # 步驟1: 添加 PointRend 的預設配置結構\n",
        "\n",
        "    pointrend_x101_yaml_path = \"detectron2_repo/projects/PointRend/configs/InstanceSegmentation/pointrend_rcnn_X_101_32x8d_FPN_3x_coco.yaml\"\n",
        "\n",
        "    if os.path.exists(pointrend_x101_yaml_path):\n",
        "        try:\n",
        "            cfg.merge_from_file(pointrend_x101_yaml_path) # 步驟2: 用 YAML 的值覆蓋\n",
        "            print(f\"已成功從 '{pointrend_x101_yaml_path}' 載入 PointRend X101 設定。\")\n",
        "\n",
        "            path_to_your_downloaded_weights = str(BASE_DIR / \"model_final_ba17b9.pkl\")\n",
        "            if os.path.exists(path_to_your_downloaded_weights):\n",
        "                cfg.MODEL.WEIGHTS = path_to_your_downloaded_weights\n",
        "                print(f\"將使用您提供的本地預訓練權重: {cfg.MODEL.WEIGHTS}\")\n",
        "            elif not cfg.MODEL.WEIGHTS:\n",
        "                print(f\"警告：YAML 未指定 MODEL.WEIGHTS，且未找到本地權重。將使用標準 ResNeXt-101 FPN 骨幹權重。\")\n",
        "                cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\")\n",
        "            else:\n",
        "                print(f\"將使用 PointRend X101 YAML 中指定的權重: {cfg.MODEL.WEIGHTS}\")\n",
        "\n",
        "            MODEL_DESCRIPTION_FOR_OUTPUT = \"PointRend_X101_PKL_v013\"\n",
        "            POINTREND_CONFIG_SUCCESSFULLY_APPLIED = True\n",
        "        except Exception as e:\n",
        "            print(f\"從 '{pointrend_x101_yaml_path}' 載入 YAML 失敗: {e}。\")\n",
        "\n",
        "            print(\"將回退到標準 ResNeXt-101 FPN 設定，並手動配置 PointRend。\")\n",
        "            cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
        "            point_rend.add_pointrend_config(cfg)\n",
        "            cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\")\n",
        "            cfg.defrost()\n",
        "            cfg.MODEL.POINT_HEAD.ENABLED = True\n",
        "            cfg.MODEL.ROI_MASK_HEAD.NAME = \"PointRendMaskHead\"\n",
        "            cfg.MODEL.ROI_MASK_HEAD.POINT_HEAD_ON = True\n",
        "            cfg.MODEL.ROI_HEADS.NAME = \"PointRendROIHeads\"\n",
        "\n",
        "            print(\"已作為回退方案，手動配置了 PointRend 組件。\")\n",
        "            MODEL_DESCRIPTION_FOR_OUTPUT = \"ManuallyCfg_PointRend_X101_v013\"\n",
        "            POINTREND_CONFIG_SUCCESSFULLY_APPLIED = True\n",
        "    else:\n",
        "        print(f\"警告：指定的 PointRend YAML 檔案 '{pointrend_x101_yaml_path}' 不存在。將嘗試手動配置 PointRend。\")\n",
        "        cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
        "        cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\")\n",
        "        cfg.defrost()\n",
        "        cfg.MODEL.POINT_HEAD.ENABLED = True\n",
        "        cfg.MODEL.ROI_MASK_HEAD.NAME = \"PointRendMaskHead\"\n",
        "        cfg.MODEL.ROI_MASK_HEAD.POINT_HEAD_ON = True\n",
        "        cfg.MODEL.ROI_HEADS.NAME = \"PointRendROIHeads\"\n",
        "        # cfg.freeze()\n",
        "        print(\"已手動配置 PointRend 組件。\")\n",
        "        MODEL_DESCRIPTION_FOR_OUTPUT = \"ManuallyCfg_PointRend_X101_v013\"\n",
        "        POINTREND_CONFIG_SUCCESSFULLY_APPLIED = True\n",
        "else:\n",
        "    print(\"PointRend 專案未正確設定或導入，將使用標準 ResNeXt-101 FPN (不含 PointRend)。\")\n",
        "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
        "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\")\n",
        "    if cfg.MODEL.get(\"POINT_HEAD\"):\n",
        "        cfg.defrost()\n",
        "        cfg.MODEL.POINT_HEAD.ENABLED = False\n",
        "        # cfg.freeze()\n",
        "    POINTREND_CONFIG_SUCCESSFULLY_APPLIED = False\n",
        "\n",
        "\n",
        "# === 針對任務進行修改 ===\n",
        "cfg.DATASETS.TRAIN = (\"cells_train\",)\n",
        "cfg.DATASETS.TEST = (\"cells_val\",)\n",
        "cfg.DATALOADER.NUM_WORKERS = 12\n",
        "\n",
        "cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# --- 設定並同步 NUM_CLASSES---\n",
        "cfg.defrost()\n",
        "# 設定 ROI_HEADS 的類別數\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(CLASS_NAMES)\n",
        "print(f\"已將 cfg.MODEL.ROI_HEADS.NUM_CLASSES 設定為: {cfg.MODEL.ROI_HEADS.NUM_CLASSES}\")\n",
        "\n",
        "if POINTREND_CONFIG_SUCCESSFULLY_APPLIED:\n",
        "\n",
        "    if not cfg.MODEL.get(\"POINT_HEAD\"):\n",
        "        print(\"錯誤：POINT_HEAD 節點未定義，即使 PointRend 被認為已配置！\")\n",
        "\n",
        "        cfg.MODEL.POINT_HEAD = CfgNode()\n",
        "        cfg.MODEL.POINT_HEAD.ENABLED = False\n",
        "        MODEL_DESCRIPTION_FOR_OUTPUT += \"_PointHeadNodeMissingError\"\n",
        "    else: # POINT_HEAD 節點存在\n",
        "        if not cfg.MODEL.POINT_HEAD.get(\"ENABLED\", False):\n",
        "            print(\"警告: POINT_HEAD.ENABLED 在配置中為 False 或未設定，現強制設為 True 以啟用 PointRend。\")\n",
        "            cfg.MODEL.POINT_HEAD.ENABLED = True\n",
        "\n",
        "        # 確保 NUM_CLASSES 屬性存在於 POINT_HEAD 中\n",
        "        if \"NUM_CLASSES\" not in cfg.MODEL.POINT_HEAD:\n",
        "             cfg.MODEL.POINT_HEAD.NUM_CLASSES = -1\n",
        "        cfg.MODEL.POINT_HEAD.NUM_CLASSES = cfg.MODEL.ROI_HEADS.NUM_CLASSES\n",
        "        print(f\"已將 cfg.MODEL.POINT_HEAD.NUM_CLASSES 同步為: {cfg.MODEL.POINT_HEAD.NUM_CLASSES}\")\n",
        "\n",
        "        # 強制設定/確認 PointRend 的關鍵頭部名稱和開關\n",
        "        expected_roi_mask_head_name = \"PointRendMaskHead\"\n",
        "        expected_roi_heads_name = \"PointRendROIHeads\"\n",
        "        if cfg.MODEL.ROI_MASK_HEAD.NAME != expected_roi_mask_head_name:\n",
        "            print(f\"將 ROI_MASK_HEAD.NAME 從 '{cfg.MODEL.ROI_MASK_HEAD.NAME}' 強制設定為 '{expected_roi_mask_head_name}'\")\n",
        "            cfg.MODEL.ROI_MASK_HEAD.NAME = expected_roi_mask_head_name\n",
        "        if not cfg.MODEL.ROI_MASK_HEAD.get(\"POINT_HEAD_ON\", False):\n",
        "             print(f\"將 ROI_MASK_HEAD.POINT_HEAD_ON 強制設定為 True\")\n",
        "             cfg.MODEL.ROI_MASK_HEAD.POINT_HEAD_ON = True\n",
        "        if cfg.MODEL.ROI_HEADS.NAME != expected_roi_heads_name:\n",
        "            print(f\"將 ROI_HEADS.NAME 從 '{cfg.MODEL.ROI_HEADS.NAME}' 強制設定為 '{expected_roi_heads_name}'\")\n",
        "            cfg.MODEL.ROI_HEADS.NAME = expected_roi_heads_name\n",
        "else: # 如果 PointRend 未被成功配置\n",
        "    if cfg.MODEL.get(\"POINT_HEAD\") and cfg.MODEL.POINT_HEAD.get(\"ENABLED\", False):\n",
        "        print(\"警告：PointRend 似乎未成功配置，但 POINT_HEAD 仍為啟用狀態。將強制禁用以避免錯誤。\")\n",
        "        cfg.MODEL.POINT_HEAD.ENABLED = False\n",
        "# --- NUM_CLASSES 設定結束 ---\n",
        "\n",
        "# === SOLVER設定 ===\n",
        "cfg.SOLVER.IMS_PER_BATCH = 4\n",
        "cfg.SOLVER.BASE_LR = 0.001\n",
        "\n",
        "cfg.SOLVER.MAX_ITER = 8000\n",
        "\n",
        "cfg.SOLVER.LR_SCHEDULER_NAME = \"WarmupCosineLR\"\n",
        "cfg.SOLVER.WARMUP_ITERS = 1000\n",
        "cfg.SOLVER.WARMUP_FACTOR = 1.0 / 1000\n",
        "cfg.SOLVER.WARMUP_METHOD = \"linear\"\n",
        "\n",
        "\n",
        "cfg.SOLVER.STEPS = []\n",
        "cfg.SOLVER.GAMMA = 0.1\n",
        "\n",
        "cfg.SOLVER.CLIP_GRADIENTS.ENABLED = True\n",
        "cfg.SOLVER.CLIP_GRADIENTS.CLIP_TYPE = \"norm\"\n",
        "cfg.SOLVER.CLIP_GRADIENTS.CLIP_VALUE = 1.0\n",
        "cfg.SOLVER.CLIP_GRADIENTS.NORM_TYPE = 2.0\n",
        "\n",
        "cfg.SOLVER.CHECKPOINT_PERIOD = 2000\n",
        "cfg.TEST.EVAL_PERIOD = 2000\n",
        "\n",
        "\n",
        "# 更新輸出目錄描述\n",
        "final_model_desc = MODEL_DESCRIPTION_FOR_OUTPUT\n",
        "cfg.OUTPUT_DIR = str(BASE_DIR / f\"output_{final_model_desc}_Warmup_Clip_8kIter_Final_v3_AssertionFix_longtrain\")\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# 在所有配置值設定完成後，凍結 cfg\n",
        "cfg.freeze()\n",
        "\n",
        "# --- 檢查模型大小 ---\n",
        "temp_model_for_param_check = build_model(cfg)\n",
        "total_parameters = sum(p.numel() for p in temp_model_for_param_check.parameters())\n",
        "trainable_parameters = sum(p.numel() for p in temp_model_for_param_check.parameters() if p.requires_grad)\n",
        "print(f\"模型：{final_model_desc}\")\n",
        "print(f\"總參數數量：{total_parameters/1e6:.2f}M\")\n",
        "print(f\"可訓練參數數量：{trainable_parameters/1e6:.2f}M\")\n",
        "del temp_model_for_param_check\n",
        "\n",
        "# --- 5. 設定訓練器並開始訓練 ---\n",
        "class CocoTrainerWithEval(DefaultTrainer):\n",
        "    @classmethod\n",
        "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "        if output_folder is None:\n",
        "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"coco_eval_val_set\")\n",
        "        return COCOEvaluator(dataset_name, cfg, distributed=False, output_dir=output_folder, use_fast_impl=False)\n",
        "\n",
        "trainer = CocoTrainerWithEval(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "try:\n",
        "    print(f\"--- 開始訓練 (模型：{final_model_desc}, 迭代次數：{cfg.SOLVER.MAX_ITER}) ---\")\n",
        "    print(f\"--- 設定檔儲存於: {cfg.OUTPUT_DIR} ---\")\n",
        "    print(f\"--- 使用的預訓練權重: {cfg.MODEL.WEIGHTS} ---\")\n",
        "    print(f\"--- ROI_HEADS.NUM_CLASSES: {cfg.MODEL.ROI_HEADS.NUM_CLASSES} ---\")\n",
        "    if cfg.MODEL.get(\"POINT_HEAD\") and cfg.MODEL.POINT_HEAD.get(\"ENABLED\"):\n",
        "        print(f\"--- POINT_HEAD.NUM_CLASSES: {cfg.MODEL.POINT_HEAD.NUM_CLASSES} ---\")\n",
        "    trainer.train()\n",
        "except Exception as e:\n",
        "    print(f\"訓練被中斷或發生錯誤: {e}\")\n",
        "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "    with open(os.path.join(cfg.OUTPUT_DIR, \"config_at_error_time.yaml\"), \"w\") as f_err:\n",
        "        f_err.write(cfg.dump())\n",
        "    raise e\n",
        "finally:\n",
        "    print(\"--- 訓練完成或已停止 ---\")\n",
        "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "    with open(os.path.join(cfg.OUTPUT_DIR, \"config_final_training.yaml\"), \"w\") as f_final:\n",
        "        f_final.write(cfg.dump())"
      ],
      "metadata": {
        "id": "f7FF5ylg5Xdf",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. 推論 ---\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
        "import json\n",
        "\n",
        "cfg.defrost()\n",
        "\n",
        "# 載入最佳或最後訓練的模型\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # 設定測試時的偵測信心度閾值\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "# 載入測試影像的元資料\n",
        "try:\n",
        "    with open(TEST_JSON_PATH, 'r') as f_json:\n",
        "        test_metadata_list_from_json = json.load(f_json)\n",
        "except FileNotFoundError:\n",
        "    print(f\"錯誤：找不到測試 JSON 檔案於 {TEST_JSON_PATH}\")\n",
        "    test_metadata_list_from_json = []\n",
        "except json.JSONDecodeError:\n",
        "    print(f\"錯誤：解析測試 JSON 檔案 {TEST_JSON_PATH} 失敗。請檢查格式。\")\n",
        "    test_metadata_list_from_json = []\n",
        "\n",
        "\n",
        "\n",
        "if isinstance(test_metadata_list_from_json, dict) and \"file_name\" in test_metadata_list_from_json:\n",
        "    print(\"偵測到 test_image_name_to_ids.json 是單一項目，將其轉換為列表。\")\n",
        "    test_metadata_list_from_json = [test_metadata_list_from_json]\n",
        "elif not isinstance(test_metadata_list_from_json, list):\n",
        "    print(f\"警告: test_image_name_to_ids.json 不是預期的列表格式。將嘗試從 {TEST_IMG_DIR} 列出 .tif 檔案。\")\n",
        "    test_metadata_list_from_json = []\n",
        "\n",
        "\n",
        "submission_output_list = []\n",
        "print(f\"\\n--- 開始為 {len(test_metadata_list_from_json)} 張測試影像產生預測 ---\")\n",
        "\n",
        "for test_image_info in test_metadata_list_from_json:\n",
        "    test_file_name = test_image_info.get(\"file_name\")\n",
        "\n",
        "    submission_image_id = test_image_info.get(\"id\")\n",
        "    expected_height = test_image_info.get(\"height\")\n",
        "    expected_width = test_image_info.get(\"width\")\n",
        "\n",
        "    if not test_file_name or submission_image_id is None:\n",
        "        print(f\"跳過項目，因缺少 'file_name' 或 'id': {test_image_info}\")\n",
        "        continue\n",
        "\n",
        "    current_test_image_path = TEST_IMG_DIR / test_file_name\n",
        "\n",
        "    if not current_test_image_path.exists():\n",
        "        print(f\"找不到測試影像: {current_test_image_path}。跳過。\")\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "\n",
        "        img_for_prediction_raw = tifffile.imread(current_test_image_path)\n",
        "        img_for_prediction = img_for_prediction_raw.copy()\n",
        "\n",
        "        if img_for_prediction.ndim == 2: img_for_prediction = cv2.cvtColor(img_for_prediction, cv2.COLOR_GRAY2RGB)\n",
        "        elif img_for_prediction.shape[2] == 1: img_for_prediction = cv2.cvtColor(img_for_prediction[:,:,0], cv2.COLOR_GRAY2RGB)\n",
        "        elif img_for_prediction.shape[2] == 4: img_for_prediction = img_for_prediction[:,:,:3]\n",
        "        elif img_for_prediction.shape[2] > 3: img_for_prediction = img_for_prediction[:,:,:3]\n",
        "\n",
        "        if img_for_prediction.dtype != np.uint8:\n",
        "            max_val_pred = np.max(img_for_prediction)\n",
        "            if max_val_pred > 0: img_for_prediction = (img_for_prediction / max_val_pred * 255).astype(np.uint8)\n",
        "            else: img_for_prediction = img_for_prediction.astype(np.uint8)\n",
        "\n",
        "        if expected_height is not None and img_for_prediction.shape[0] != expected_height:\n",
        "            print(f\"警告：影像 {test_file_name} 的高度 ({img_for_prediction.shape[0]}) 與 JSON 中的高度 ({expected_height}) 不符。\")\n",
        "        if expected_width is not None and img_for_prediction.shape[1] != expected_width:\n",
        "            print(f\"警告：影像 {test_file_name} 的寬度 ({img_for_prediction.shape[1]}) 與 JSON 中的寬度 ({expected_width}) 不符。\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"讀取或處理測試影像 {current_test_image_path} 時發生錯誤: {e}。跳過。\")\n",
        "        continue\n",
        "\n",
        "\n",
        "    prediction_outputs = predictor(img_for_prediction)\n",
        "\n",
        "    instances = prediction_outputs[\"instances\"].to(\"cpu\")\n",
        "    predicted_masks_tensor = instances.pred_masks\n",
        "    predicted_boxes_obj = instances.pred_boxes\n",
        "    predicted_classes_tensor = instances.pred_classes\n",
        "    predicted_scores_tensor = instances.scores\n",
        "\n",
        "    num_detected_instances = len(instances)\n",
        "\n",
        "\n",
        "    for i in range(num_detected_instances):\n",
        "        binary_mask_numpy = predicted_masks_tensor[i].numpy().astype(np.uint8)\n",
        "        class_id_0_indexed = predicted_classes_tensor[i].item()\n",
        "        score_val = predicted_scores_tensor[i].item()\n",
        "        bbox_coords_xyxy = predicted_boxes_obj[i].tensor.numpy()[0].tolist()\n",
        "\n",
        "\n",
        "        submission_category_id = class_id_0_indexed + 1\n",
        "\n",
        "\n",
        "        rle_encoded_mask = mask_util.encode(np.asfortranarray(binary_mask_numpy))\n",
        "\n",
        "        rle_encoded_mask['counts'] = rle_encoded_mask['counts'].decode('utf-8')\n",
        "\n",
        "\n",
        "        submission_output_list.append({\n",
        "            \"image_id\": submission_image_id,\n",
        "            \"bbox\": bbox_coords_xyxy,\n",
        "            \"score\": float(score_val),\n",
        "            \"category_id\": submission_category_id,\n",
        "            \"segmentation\": rle_encoded_mask\n",
        "        })\n",
        "\n",
        "# 儲存提交檔案\n",
        "submission_file_output_path = BASE_DIR / \"test-results.json\"\n",
        "    with open(submission_file_output_path, 'w') as f_submit:\n",
        "        json.dump(submission_output_list, f_submit, indent=2)\n",
        "    print(f\"\\n提交檔案已儲存至: {submission_file_output_path}\")\n",
        "    print(f\"提交檔案中總實例數: {len(submission_output_list)}\")\n",
        "except Exception as e:\n",
        "    print(f\"儲存提交檔案時發生錯誤: {e}\")\n",
        "\n",
        "\n",
        "#--- 測試影像上視覺化預測結果 ---\n",
        "print(\"\\n--- 視覺化一些測試影像的預測結果 ---\")\n",
        "num_test_images_to_visualize = min(3, len(test_metadata_list_from_json))\n",
        "if num_test_images_to_visualize > 0:\n",
        "    for i in range(num_test_images_to_visualize):\n",
        "        if not test_metadata_list_from_json: break\n",
        "        # 隨機選擇一個測試影像進行視覺化\n",
        "        test_image_info_for_viz = random.choice(test_metadata_list_from_json)\n",
        "        viz_file_name = test_image_info_for_viz.get(\"file_name\")\n",
        "        if not viz_file_name: continue\n",
        "        viz_img_path = TEST_IMG_DIR / viz_file_name\n",
        "        if not viz_img_path.exists(): continue\n",
        "\n",
        "        try:\n",
        "            viz_img_raw = tifffile.imread(viz_img_path)\n",
        "            viz_img_processed = viz_img_raw.copy()\n",
        "\n",
        "            if viz_img_processed.ndim == 2: viz_img_processed = cv2.cvtColor(viz_img_processed, cv2.COLOR_GRAY2RGB)\n",
        "            elif viz_img_processed.shape[2] == 1: viz_img_processed = cv2.cvtColor(viz_img_processed[:,:,0], cv2.COLOR_GRAY2RGB)\n",
        "            elif viz_img_processed.shape[2] == 4: viz_img_processed = viz_img_processed[:,:,:3]\n",
        "            elif viz_img_processed.shape[2] > 3: viz_img_processed = viz_img_processed[:,:,:3]\n",
        "\n",
        "            if viz_img_processed.dtype != np.uint8:\n",
        "                max_val_viz_display = np.max(viz_img_processed)\n",
        "                if max_val_viz_display > 0: viz_img_display = (viz_img_processed / max_val_viz_display * 255).astype(np.uint8)\n",
        "                else: viz_img_display = viz_img_processed.astype(np.uint8)\n",
        "            else:\n",
        "                viz_img_display = viz_img_processed\n",
        "\n",
        "            viz_outputs = predictor(viz_img_processed)\n",
        "\n",
        "            v = Visualizer(viz_img_display[:, :, ::-1],\n",
        "                           metadata=MetadataCatalog.get(\"cells_train\"),\n",
        "                           scale=0.6,\n",
        "                           instance_mode=ColorMode.IMAGE_BW\n",
        "            )\n",
        "            out_visualization = v.draw_instance_predictions(viz_outputs[\"instances\"].to(\"cpu\"))\n",
        "            print(f\"正在顯示 {viz_file_name} 的預測結果\")\n",
        "            cv2_imshow(out_visualization.get_image()[:, :, ::-1])\n",
        "        except Exception as e_viz:\n",
        "            print(f\"載入/視覺化測試影像 {viz_img_path} 時發生錯誤: {e_viz}\")\n",
        "\n",
        "print(\"\\n--- 執行完畢 ---\")"
      ],
      "metadata": {
        "id": "xzConwLGuk6y",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "\n",
        "metrics_original_file_path = \"/content/drive/MyDrive/hw3-data-release/output_PointRend_X101_PKL_v013_Warmup_Clip_8kIter_Final_v3_AssertionFix/metrics.json\"\n",
        "\n",
        "print(f\"將嘗試讀取原始 metrics 檔案: {metrics_original_file_path}\")\n",
        "\n",
        "# --- 1. 讀取與解析 metrics.json ---\n",
        "data_list_all = []\n",
        "try:\n",
        "    with open(metrics_original_file_path, 'r') as f:\n",
        "        for line_number, line in enumerate(f):\n",
        "            try:\n",
        "                clean_line = line.strip()\n",
        "                if clean_line.endswith(','):\n",
        "                    clean_line = clean_line[:-1]\n",
        "                if clean_line:\n",
        "                    data_list_all.append(json.loads(clean_line))\n",
        "            except json.JSONDecodeError:\n",
        "                print(f\"警告：跳過無法解析的 JSON 行 (行號 {line_number + 1}): {line.strip()}\")\n",
        "\n",
        "    if not data_list_all:\n",
        "        print(f\"錯誤：從 '{metrics_original_file_path}' 未讀取到任何有效數據。\")\n",
        "        df_metrics_raw_all = pd.DataFrame()\n",
        "    else:\n",
        "        df_metrics_raw_all = pd.DataFrame(data_list_all)\n",
        "        print(f\"成功讀取原始 metrics.json，共 {len(df_metrics_raw_all)} 條記錄。\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"錯誤：找不到 metrics.json 檔案於 '{metrics_original_file_path}'。\")\n",
        "    df_metrics_raw_all = pd.DataFrame()\n",
        "except Exception as e:\n",
        "    print(f\"讀取 metrics.json 時發生其他錯誤: {e}\")\n",
        "    df_metrics_raw_all = pd.DataFrame()\n",
        "\n",
        "# --- 2. 偵測最後一次訓練運行的起始索引 ---\n",
        "def find_last_run_start_index(df_raw):\n",
        "    \"\"\"\n",
        "    偵測包含多次運行記錄的 DataFrame 中，最後一次運行的起始索引。\n",
        "    依據是尋找迭代次數 (iteration) 的重置點。\n",
        "    \"\"\"\n",
        "    last_run_start_idx = 0\n",
        "    if df_raw.empty or 'iteration' not in df_raw.columns:\n",
        "        print(\"DataFrame 為空或缺少 'iteration' 列，無法偵測運行起始。\")\n",
        "        return last_run_start_idx\n",
        "\n",
        "    iterations_num = pd.to_numeric(df_raw['iteration'], errors='coerce')\n",
        "    valid_indices_mask = iterations_num.notna()\n",
        "\n",
        "    if not valid_indices_mask.any():\n",
        "        print(\"未找到有效的數值迭代記錄，無法偵測運行起始。\")\n",
        "        return last_run_start_idx\n",
        "\n",
        "    valid_iterations = iterations_num[valid_indices_mask]\n",
        "    valid_original_indices = df_raw.index[valid_indices_mask]\n",
        "\n",
        "    if len(valid_iterations) <= 1:\n",
        "        return valid_original_indices[0] if len(valid_iterations) == 1 else 0\n",
        "\n",
        "    prev_iter_val = valid_iterations.iloc[0]\n",
        "    last_run_start_idx = valid_original_indices[0]\n",
        "\n",
        "\n",
        "    for i in range(1, len(valid_iterations)):\n",
        "        current_original_index = valid_original_indices[i]\n",
        "        current_iter_val = valid_iterations.iloc[i]\n",
        "\n",
        "        reset_detected = False\n",
        "\n",
        "        if prev_iter_val > 1000 and current_iter_val < 100:\n",
        "            reset_detected = True\n",
        "\n",
        "        elif current_iter_val < prev_iter_val and (prev_iter_val - current_iter_val) > 500:\n",
        "             reset_detected = True\n",
        "\n",
        "\n",
        "        if reset_detected:\n",
        "            last_run_start_idx = current_original_index\n",
        "            print(f\"檢測到潛在運行重置於原始索引 {current_original_index} (迭代 {int(current_iter_val)} 在 {int(prev_iter_val)} 之後)。設定新的起始點。\")\n",
        "\n",
        "        prev_iter_val = current_iter_val\n",
        "\n",
        "    print(f\"最終識別的最後一次訓練運行起始原始索引為: {last_run_start_idx}\")\n",
        "    return last_run_start_idx\n",
        "\n",
        "# --- 3. 選取最後一次運行的數據並進行預處理 ---\n",
        "df_metrics_processed = pd.DataFrame() # 初始化\n",
        "if not df_metrics_raw_all.empty:\n",
        "    last_run_start_idx = find_last_run_start_index(df_metrics_raw_all)\n",
        "\n",
        "    df_last_run_raw = df_metrics_raw_all.loc[last_run_start_idx:].copy()\n",
        "    print(f\"已選取最後一次運行的原始記錄 {len(df_last_run_raw)} 條 (從索引 {last_run_start_idx} 開始)。\")\n",
        "\n",
        "    if not df_last_run_raw.empty and 'iteration' in df_last_run_raw.columns:\n",
        "\n",
        "        df_last_run_raw['iteration'] = pd.to_numeric(df_last_run_raw['iteration'], errors='coerce')\n",
        "        df_last_run_raw = df_last_run_raw.dropna(subset=['iteration'])\n",
        "\n",
        "        if not df_last_run_raw.empty:\n",
        "            df_last_run_raw['iteration'] = df_last_run_raw['iteration'].astype(int)\n",
        "\n",
        "            df_metrics_processed = df_last_run_raw.drop_duplicates(subset=['iteration'], keep='last').sort_values(by='iteration')\n",
        "            print(f\"處理最後一次運行的重複迭代並排序後，剩餘 {len(df_metrics_processed)} 條記錄用於分析。\")\n",
        "        else:\n",
        "            print(\"在選取的最後一次運行數據中，未能找到有效的迭代記錄。\")\n",
        "    else:\n",
        "        print(\"選取的最後一次運行數據為空或缺少 'iteration' 列。\")\n",
        "else:\n",
        "    print(\"原始 DataFrame 為空，無法進行數據選取和處理。\")\n",
        "\n",
        "# --- 4. 繪製圖表 (使用處理後的最後一次運行的數據) ---\n",
        "if not df_metrics_processed.empty and 'iteration' in df_metrics_processed.columns:\n",
        "\n",
        "    # --- 4.1 繪製訓練損失曲線 ---\n",
        "    loss_cols = {\n",
        "        'total_loss': 'Total Loss', 'loss_mask': 'Mask Loss', 'loss_mask_point': 'PointRend Loss',\n",
        "        'loss_cls': 'Cls Loss', 'loss_box_reg': 'BoxReg Loss',\n",
        "        'loss_rpn_cls': 'RPN Cls Loss', 'loss_rpn_loc': 'RPN Loc Loss',\n",
        "    }\n",
        "    available_losses = {k: v for k, v in loss_cols.items() if k in df_metrics_processed.columns}\n",
        "\n",
        "    if available_losses:\n",
        "        df_train_log_plot = df_metrics_processed[df_metrics_processed[list(available_losses.keys())].notna().any(axis=1)].copy()\n",
        "        if not df_train_log_plot.empty:\n",
        "            plt.figure(figsize=(15, 8))\n",
        "            for col, label in available_losses.items():\n",
        "                if col in df_train_log_plot.columns and df_train_log_plot[col].notna().any():\n",
        "                    plt.plot(df_train_log_plot['iteration'], df_train_log_plot[col], label=label, alpha=0.9)\n",
        "            plt.xlabel('Iteration (Last Run)')\n",
        "            plt.ylabel('Loss Value')\n",
        "            plt.title('Training Losses Over Iterations (Last Run Only)')\n",
        "            plt.legend(loc='best')\n",
        "            plt.grid(True)\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "        else: print(\"在最後運行數據中未找到有效的訓練損失記錄。\")\n",
        "    else: print(\"在最後運行數據中未找到任何可繪製的損失欄位。\")\n",
        "\n",
        "    # --- 4.2 繪製學習率變化 ---\n",
        "    if 'lr' in df_metrics_processed.columns:\n",
        "        df_lr_log_plot = df_metrics_processed[df_metrics_processed['lr'].notna()].copy()\n",
        "        if not df_lr_log_plot.empty:\n",
        "            plt.figure(figsize=(15, 5))\n",
        "            plt.plot(df_lr_log_plot['iteration'], df_lr_log_plot['lr'], label='Learning Rate', color='g')\n",
        "            plt.xlabel('Iteration (Last Run)')\n",
        "            plt.ylabel('Learning Rate')\n",
        "            plt.title('Learning Rate Schedule Over Iterations (Last Run Only)')\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "        else: print(\"在最後運行數據中未找到有效的學習率記錄。\")\n",
        "    else: print(\"在最後運行數據中未找到 'lr' 欄位。\")\n",
        "\n",
        "    # --- 4.3 繪製驗證集實例分割 AP ---\n",
        "    segm_ap_cols = {\n",
        "        'segm/AP': 'AP', 'segm/AP50': 'AP50', 'segm/AP75': 'AP75',\n",
        "        'segm/APs': 'APs', 'segm/APm': 'APm',\n",
        "    }\n",
        "    available_segm_aps = {k: v for k, v in segm_ap_cols.items() if k in df_metrics_processed.columns}\n",
        "\n",
        "    if available_segm_aps:\n",
        "        df_eval_segm_plot = df_metrics_processed[df_metrics_processed[list(available_segm_aps.keys())].notna().any(axis=1)].copy()\n",
        "        if not df_eval_segm_plot.empty:\n",
        "            plt.figure(figsize=(15, 8))\n",
        "            for col, label in available_segm_aps.items():\n",
        "                 if col in df_eval_segm_plot.columns and df_eval_segm_plot[col].notna().any():\n",
        "                    numeric_values = pd.to_numeric(df_eval_segm_plot[col], errors='coerce').replace(-1.0, np.nan)\n",
        "                    if not numeric_values.isna().all():\n",
        "                        plt.plot(df_eval_segm_plot['iteration'], numeric_values, marker='o', linestyle='-', label=label)\n",
        "            plt.xlabel('Iteration (Last Run)')\n",
        "            plt.ylabel('Segmentation AP Score')\n",
        "            plt.title('Validation Segmentation AP Over Iterations (Last Run Only)')\n",
        "            plt.legend(loc='best')\n",
        "            plt.grid(True)\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "        else: print(\"在最後運行數據中未找到有效的分割 AP 記錄。\")\n",
        "    else: print(\"在最後運行數據中未找到任何可繪製的分割 AP 欄位。\")\n",
        "\n",
        "\n",
        "else:\n",
        "    print(\"無法進行繪圖，因為處理後的 DataFrame 為空或缺少 'iteration' 列。\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "PcrDIkbNq5EZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}