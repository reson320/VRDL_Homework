{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 安裝必要套件\n",
        "!pip install timm einops matplotlib pillow scikit-image"
      ],
      "metadata": {
        "id": "6dEyD9rNIpwa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "d4f7a9e6-d85e-4f11-e781-7a3306c55d63"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.15)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.21.0+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.31.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.15.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.5.10)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2025.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.13.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->timm)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->timm)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->timm)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->timm)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->timm)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->timm)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.4.26)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m130.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m111.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsxhhjtNITxi"
      },
      "outputs": [],
      "source": [
        "# 導入必要的庫\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "import math\n",
        "import random\n",
        "from einops import rearrange\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 設置設備\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'使用設備: {device}')\n",
        "# 設置隨機種子\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MDTA(nn.Module):\n",
        "    \"\"\"Multi-Dconv Head Transposed Attention\"\"\"\n",
        "    def __init__(self, channels, num_heads):\n",
        "        super(MDTA, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.temperature = nn.Parameter(torch.ones(num_heads, 1, 1))\n",
        "\n",
        "        self.qkv = nn.Conv2d(channels, channels * 3, kernel_size=1, bias=False)\n",
        "        self.qkv_dwconv = nn.Conv2d(channels * 3, channels * 3, kernel_size=3,\n",
        "                                   stride=1, padding=1, groups=channels * 3, bias=False)\n",
        "        self.project_out = nn.Conv2d(channels, channels, kernel_size=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "\n",
        "        qkv = self.qkv_dwconv(self.qkv(x))\n",
        "        q, k, v = qkv.chunk(3, dim=1)\n",
        "\n",
        "        q = rearrange(q, 'b (head c) h w -> b head c (h w)', head=self.num_heads)\n",
        "        k = rearrange(k, 'b (head c) h w -> b head c (h w)', head=self.num_heads)\n",
        "        v = rearrange(v, 'b (head c) h w -> b head c (h w)', head=self.num_heads)\n",
        "\n",
        "        q = torch.nn.functional.normalize(q, dim=-1)\n",
        "        k = torch.nn.functional.normalize(k, dim=-1)\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.temperature\n",
        "        attn = attn.softmax(dim=-1)\n",
        "\n",
        "        out = (attn @ v)\n",
        "        out = rearrange(out, 'b head c (h w) -> b (head c) h w', head=self.num_heads, h=h, w=w)\n",
        "        out = self.project_out(out)\n",
        "        return out\n",
        "\n",
        "class GDFN(nn.Module):\n",
        "    \"\"\"Gated-Dconv Feed-Forward Network\"\"\"\n",
        "    def __init__(self, channels, expansion_factor):\n",
        "        super(GDFN, self).__init__()\n",
        "\n",
        "        hidden_channels = int(channels * expansion_factor)\n",
        "        self.project_in = nn.Conv2d(channels, hidden_channels * 2, kernel_size=1, bias=False)\n",
        "        self.dwconv = nn.Conv2d(hidden_channels * 2, hidden_channels * 2, kernel_size=3,\n",
        "                               stride=1, padding=1, groups=hidden_channels * 2, bias=False)\n",
        "        self.project_out = nn.Conv2d(hidden_channels, channels, kernel_size=1, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.project_in(x)\n",
        "        x1, x2 = self.dwconv(x).chunk(2, dim=1)\n",
        "        x = torch.nn.functional.gelu(x1) * x2\n",
        "        x = self.project_out(x)\n",
        "        return x\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    \"\"\"Restormer Transformer Block\"\"\"\n",
        "    def __init__(self, channels, num_heads, expansion_factor):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(channels)\n",
        "        self.attn = MDTA(channels, num_heads)\n",
        "        self.norm2 = nn.LayerNorm(channels)\n",
        "        self.ffn = GDFN(channels, expansion_factor)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "\n",
        "        # Attention\n",
        "        res = x\n",
        "        x = x.flatten(2).transpose(1, 2)  # (B, H*W, C)\n",
        "        x = self.norm1(x)\n",
        "        x = x.transpose(1, 2).view(b, c, h, w)  # (B, C, H, W)\n",
        "        x = self.attn(x) + res\n",
        "\n",
        "        # FFN\n",
        "        res = x\n",
        "        x = x.flatten(2).transpose(1, 2)  # (B, H*W, C)\n",
        "        x = self.norm2(x)\n",
        "        x = x.transpose(1, 2).view(b, c, h, w)  # (B, C, H, W)\n",
        "        x = self.ffn(x) + res\n",
        "\n",
        "        return x\n",
        "\n",
        "class Restormer(nn.Module):\n",
        "    \"\"\"完整的 Restormer 模型\"\"\"\n",
        "    def __init__(self,\n",
        "                 inp_channels=3,\n",
        "                 out_channels=3,\n",
        "                 dim=32,\n",
        "                 num_blocks=[4,6,6,8],\n",
        "                 num_refinement_blocks=4,\n",
        "                 heads=[1,2,4,8],\n",
        "                 ffn_expansion_factor=2.66,\n",
        "                 bias=False,\n",
        "                 LayerNorm_type='WithBias'):\n",
        "        super(Restormer, self).__init__()\n",
        "\n",
        "        self.patch_embed = OverlapPatchEmbed(inp_channels, dim)\n",
        "\n",
        "        self.encoder_level1 = nn.Sequential(*[TransformerBlock(channels=dim, num_heads=heads[0],\n",
        "                                                               expansion_factor=ffn_expansion_factor)\n",
        "                                             for i in range(num_blocks[0])])\n",
        "\n",
        "        self.down1_2 = Downsample(dim) ## From Level 1 to Level 2\n",
        "        self.encoder_level2 = nn.Sequential(*[TransformerBlock(channels=int(dim*2**1), num_heads=heads[1],\n",
        "                                                               expansion_factor=ffn_expansion_factor)\n",
        "                                             for i in range(num_blocks[1])])\n",
        "\n",
        "        self.down2_3 = Downsample(int(dim*2**1)) ## From Level 2 to Level 3\n",
        "        self.encoder_level3 = nn.Sequential(*[TransformerBlock(channels=int(dim*2**2), num_heads=heads[2],\n",
        "                                                               expansion_factor=ffn_expansion_factor)\n",
        "                                             for i in range(num_blocks[2])])\n",
        "\n",
        "        self.down3_4 = Downsample(int(dim*2**2)) ## From Level 3 to Level 4\n",
        "        self.latent = nn.Sequential(*[TransformerBlock(channels=int(dim*2**3), num_heads=heads[3],\n",
        "                                                       expansion_factor=ffn_expansion_factor)\n",
        "                                     for i in range(num_blocks[3])])\n",
        "\n",
        "        self.up4_3 = Upsample(int(dim*2**3)) ## From Level 4 to Level 3\n",
        "        self.reduce_chan_level3 = nn.Conv2d(int(dim*2**3), int(dim*2**2), kernel_size=1, bias=bias)\n",
        "        self.decoder_level3 = nn.Sequential(*[TransformerBlock(channels=int(dim*2**2), num_heads=heads[2],\n",
        "                                                               expansion_factor=ffn_expansion_factor)\n",
        "                                             for i in range(num_blocks[2])])\n",
        "\n",
        "\n",
        "        self.up3_2 = Upsample(int(dim*2**2)) ## From Level 3 to Level 2\n",
        "        self.reduce_chan_level2 = nn.Conv2d(int(dim*2**2), int(dim*2**1), kernel_size=1, bias=bias)\n",
        "        self.decoder_level2 = nn.Sequential(*[TransformerBlock(channels=int(dim*2**1), num_heads=heads[1],\n",
        "                                                               expansion_factor=ffn_expansion_factor)\n",
        "                                             for i in range(num_blocks[1])])\n",
        "\n",
        "        self.up2_1 = Upsample(int(dim*2**1))  ## From Level 2 to Level 1  (NO 1x1 conv to reduce channels)\n",
        "\n",
        "        self.decoder_level1 = nn.Sequential(*[TransformerBlock(channels=int(dim*2**1), num_heads=heads[0],\n",
        "                                                               expansion_factor=ffn_expansion_factor)\n",
        "                                             for i in range(num_blocks[0])])\n",
        "\n",
        "        self.refinement = nn.Sequential(*[TransformerBlock(channels=int(dim*2**1), num_heads=heads[0],\n",
        "                                                           expansion_factor=ffn_expansion_factor)\n",
        "                                         for i in range(num_refinement_blocks)])\n",
        "\n",
        "        self.output = nn.Conv2d(int(dim*2**1), out_channels, kernel_size=3, stride=1, padding=1, bias=bias)\n",
        "\n",
        "\n",
        "    def forward(self, inp_img):\n",
        "\n",
        "        inp_enc_level1 = self.patch_embed(inp_img)\n",
        "        out_enc_level1 = self.encoder_level1(inp_enc_level1)\n",
        "\n",
        "        inp_enc_level2 = self.down1_2(out_enc_level1)\n",
        "        out_enc_level2 = self.encoder_level2(inp_enc_level2)\n",
        "\n",
        "        inp_enc_level3 = self.down2_3(out_enc_level2)\n",
        "        out_enc_level3 = self.encoder_level3(inp_enc_level3)\n",
        "\n",
        "        inp_enc_level4 = self.down3_4(out_enc_level3)\n",
        "        latent = self.latent(inp_enc_level4)\n",
        "\n",
        "        inp_dec_level3 = self.up4_3(latent)\n",
        "        inp_dec_level3 = torch.cat([inp_dec_level3, out_enc_level3], 1)\n",
        "        inp_dec_level3 = self.reduce_chan_level3(inp_dec_level3)\n",
        "        out_dec_level3 = self.decoder_level3(inp_dec_level3)\n",
        "\n",
        "        inp_dec_level2 = self.up3_2(out_dec_level3)\n",
        "        inp_dec_level2 = torch.cat([inp_dec_level2, out_enc_level2], 1)\n",
        "        inp_dec_level2 = self.reduce_chan_level2(inp_dec_level2)\n",
        "        out_dec_level2 = self.decoder_level2(inp_dec_level2)\n",
        "\n",
        "        inp_dec_level1 = self.up2_1(out_dec_level2)\n",
        "        inp_dec_level1 = torch.cat([inp_dec_level1, out_enc_level1], 1)\n",
        "        out_dec_level1 = self.decoder_level1(inp_dec_level1)\n",
        "\n",
        "        out_dec_level1 = self.refinement(out_dec_level1)\n",
        "\n",
        "        out = self.output(out_dec_level1) + inp_img\n",
        "\n",
        "        return out\n",
        "\n",
        "class OverlapPatchEmbed(nn.Module):\n",
        "    \"\"\"重疊 Patch 嵌入層\"\"\"\n",
        "    def __init__(self, in_c=3, embed_dim=48, bias=False):\n",
        "        super(OverlapPatchEmbed, self).__init__()\n",
        "        self.proj = nn.Conv2d(in_c, embed_dim, kernel_size=3, stride=1, padding=1, bias=bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.proj(x)\n",
        "        return x\n",
        "\n",
        "class Downsample(nn.Module):\n",
        "    \"\"\"下採樣層\"\"\"\n",
        "    def __init__(self, n_feat):\n",
        "        super(Downsample, self).__init__()\n",
        "        self.body = nn.Sequential(nn.Conv2d(n_feat, n_feat//2, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "                                  nn.PixelUnshuffle(2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.body(x)\n",
        "\n",
        "class Upsample(nn.Module):\n",
        "    \"\"\"上採樣層\"\"\"\n",
        "    def __init__(self, n_feat):\n",
        "        super(Upsample, self).__init__()\n",
        "        self.body = nn.Sequential(nn.Conv2d(n_feat, n_feat*2, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "                                  nn.PixelShuffle(2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.body(x)\n"
      ],
      "metadata": {
        "id": "jnzuoWTjInKW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageRestorationDataset(Dataset):\n",
        "    \"\"\"圖像修復數據集\"\"\"\n",
        "    def __init__(self, degraded_dir, clean_dir, transform=None, is_train=True):\n",
        "        self.degraded_dir = degraded_dir\n",
        "        self.clean_dir = clean_dir\n",
        "        self.transform = transform\n",
        "        self.is_train = is_train\n",
        "\n",
        "        # 獲取所有降質圖像文件名\n",
        "        self.degraded_images = []\n",
        "        if is_train:\n",
        "            # 訓練模式：有乾淨圖像對應\n",
        "            for img_name in os.listdir(degraded_dir):\n",
        "                if img_name.endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    self.degraded_images.append(img_name)\n",
        "        else:\n",
        "            # 測試模式：只有降質圖像\n",
        "            for img_name in os.listdir(degraded_dir):\n",
        "                if img_name.endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    self.degraded_images.append(img_name)\n",
        "\n",
        "        self.degraded_images.sort()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.degraded_images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # 載入降質圖像\n",
        "        degraded_path = os.path.join(self.degraded_dir, self.degraded_images[idx])\n",
        "        degraded_img = Image.open(degraded_path).convert('RGB')\n",
        "\n",
        "        if self.is_train:\n",
        "            # 訓練模式：載入對應的乾淨圖像\n",
        "            img_name = self.degraded_images[idx]\n",
        "            # 找到對應的乾淨圖像\n",
        "            if img_name.startswith('rain-'):\n",
        "                clean_name = img_name.replace('rain-', 'rain_clean-')\n",
        "            elif img_name.startswith('snow-'):\n",
        "                clean_name = img_name.replace('snow-', 'snow_clean-')\n",
        "            else:\n",
        "                clean_name = img_name  # 備用方案\n",
        "\n",
        "            clean_path = os.path.join(self.clean_dir, clean_name)\n",
        "            clean_img = Image.open(clean_path).convert('RGB')\n",
        "\n",
        "            if self.transform:\n",
        "                degraded_img = self.transform(degraded_img)\n",
        "                clean_img = self.transform(clean_img)\n",
        "\n",
        "            return {\n",
        "                'degraded': degraded_img,\n",
        "                'clean': clean_img,\n",
        "                'filename': self.degraded_images[idx]\n",
        "            }\n",
        "        else:\n",
        "            # 測試模式：只返回降質圖像\n",
        "            if self.transform:\n",
        "                degraded_img = self.transform(degraded_img)\n",
        "\n",
        "            return {\n",
        "                'degraded': degraded_img,\n",
        "                'filename': self.degraded_images[idx]\n",
        "            }\n",
        "\n",
        "# 定義數據轉換\n",
        "def get_transforms(is_train=True):\n",
        "    if is_train:\n",
        "        return transforms.Compose([\n",
        "            transforms.RandomCrop(256),  # 隨機裁剪到 256x256\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "    else:\n",
        "        return transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "#掛載雲端\n",
        "from dataclasses import dataclass\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# 設置數據路徑\n",
        "train_degraded_dir = '/content/drive/MyDrive/DL_HW/hw4_realse_dataset/train/degraded'\n",
        "train_clean_dir = '/content/drive/MyDrive/DL_HW/hw4_realse_dataset/train/clean'\n",
        "test_degraded_dir = '/content/drive/MyDrive/DL_HW/hw4_realse_dataset/test/degraded'\n",
        "\n",
        "# 建立數據載入器\n",
        "train_transform = get_transforms(is_train=True)\n",
        "test_transform = get_transforms(is_train=False)\n",
        "\n",
        "train_dataset = ImageRestorationDataset(train_degraded_dir, train_clean_dir,\n",
        "                                       transform=train_transform, is_train=True)\n",
        "test_dataset = ImageRestorationDataset(test_degraded_dir, None,\n",
        "                                      transform=test_transform, is_train=False)\n",
        "\n",
        "print(f'訓練數據集大小: {len(train_dataset)}')\n",
        "print(f'測試數據集大小: {len(test_dataset)}')\n",
        "\n",
        "# 建立 DataLoader\n",
        "batch_size = 4\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=6)"
      ],
      "metadata": {
        "id": "5chEb5NfInMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_psnr(img1, img2, max_val=1.0):\n",
        "\n",
        "    mse = torch.mean((img1 - img2) ** 2)\n",
        "    if mse == 0:\n",
        "        return float('inf')\n",
        "    psnr = 20 * torch.log10(max_val / torch.sqrt(mse))\n",
        "    return psnr.item()\n",
        "\n",
        "class CharbonnierLoss(nn.Module):\n",
        "\n",
        "    def __init__(self, eps=1e-3):\n",
        "        super(CharbonnierLoss, self).__init__()\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        diff = x - y\n",
        "        loss = torch.mean(torch.sqrt((diff * diff) + (self.eps * self.eps)))\n",
        "        return loss\n",
        "\n",
        "# 初始化模型\n",
        "model = Restormer(\n",
        "    inp_channels=3,\n",
        "    out_channels=3,\n",
        "    dim=48,\n",
        "    num_blocks=[4,6,6,8],\n",
        "    num_refinement_blocks=4,\n",
        "    heads=[1,2,4,8],\n",
        "    ffn_expansion_factor=2.66,\n",
        "    bias=False\n",
        ").to(device)\n",
        "\n",
        "# 計算模型參數數量\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f'總參數數量: {total_params:,}')\n",
        "print(f'可訓練參數數量: {trainable_params:,}')\n",
        "\n",
        "\n",
        "# 設置優化器和損失函數\n",
        "criterion = CharbonnierLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)\n",
        "\n"
      ],
      "metadata": {
        "id": "87s1EAKZInTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "# 確保所有必要的類都已定義\n",
        "import math\n",
        "import os\n",
        "import torch\n",
        "\n",
        "# WarmupCosineAnnealingLR 類定義\n",
        "class WarmupCosineAnnealingLR:\n",
        "    def __init__(self, optimizer, warmup_epochs, total_epochs, warmup_start_lr=1e-6, base_lr=3e-4, eta_min=1e-6):\n",
        "        self.optimizer = optimizer\n",
        "        self.warmup_epochs = warmup_epochs\n",
        "        self.total_epochs = total_epochs\n",
        "        self.warmup_start_lr = warmup_start_lr\n",
        "        self.base_lr = base_lr\n",
        "        self.eta_min = eta_min\n",
        "        self.current_epoch = 0\n",
        "\n",
        "        # 設置初始學習率（只在有優化器時執行）\n",
        "        if self.optimizer is not None:\n",
        "            for param_group in self.optimizer.param_groups:\n",
        "                param_group['lr'] = self.warmup_start_lr\n",
        "\n",
        "    def step(self):\n",
        "        self.current_epoch += 1\n",
        "\n",
        "        if self.current_epoch <= self.warmup_epochs:\n",
        "            # Warmup 階段：線性增長\n",
        "            lr = self.warmup_start_lr + (self.base_lr - self.warmup_start_lr) * (self.current_epoch / self.warmup_epochs)\n",
        "        else:\n",
        "            # Cosine annealing 階段\n",
        "            cosine_epochs = self.total_epochs - self.warmup_epochs\n",
        "            current_cosine_epoch = self.current_epoch - self.warmup_epochs\n",
        "            lr = self.eta_min + (self.base_lr - self.eta_min) * (\n",
        "                1 + math.cos(math.pi * current_cosine_epoch / cosine_epochs)\n",
        "            ) / 2\n",
        "\n",
        "        # 應用學習率（只在有優化器時執行）\n",
        "        if self.optimizer is not None:\n",
        "            for param_group in self.optimizer.param_groups:\n",
        "                param_group['lr'] = lr\n",
        "\n",
        "        return lr\n",
        "\n",
        "    def get_lr(self):\n",
        "        if self.optimizer is not None:\n",
        "            return self.optimizer.param_groups[0]['lr']\n",
        "        else:\n",
        "            # 如果沒有優化器，計算當前應該的學習率\n",
        "            if self.current_epoch <= self.warmup_epochs:\n",
        "                return self.warmup_start_lr + (self.base_lr - self.warmup_start_lr) * (self.current_epoch / self.warmup_epochs)\n",
        "            else:\n",
        "                cosine_epochs = self.total_epochs - self.warmup_epochs\n",
        "                current_cosine_epoch = self.current_epoch - self.warmup_epochs\n",
        "                return self.eta_min + (self.base_lr - self.eta_min) * (\n",
        "                    1 + math.cos(math.pi * current_cosine_epoch / cosine_epochs)\n",
        "                ) / 2\n",
        "\n",
        "# EarlyStopping\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=7, min_delta=0.001, restore_best_weights=True, mode='max'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): 等待改善的 epoch 數量\n",
        "            min_delta (float): 最小改善幅度，低於此值不算改善\n",
        "            restore_best_weights (bool): 是否在停止時恢復最佳權重\n",
        "            mode (str): 'max' for maximizing (PSNR), 'min' for minimizing (loss)\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.restore_best_weights = restore_best_weights\n",
        "        self.mode = mode\n",
        "\n",
        "        # 內部狀態\n",
        "        self.wait = 0\n",
        "        self.stopped_epoch = 0\n",
        "        self.best_score = None\n",
        "        self.best_weights = None\n",
        "        self.early_stop = False\n",
        "\n",
        "        # 設置比較函數\n",
        "        if mode == 'max':\n",
        "            self.monitor_op = lambda current, best: current > best + min_delta\n",
        "        else:  # mode == 'min'\n",
        "            self.monitor_op = lambda current, best: current < best - min_delta\n",
        "\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "\n",
        "        self.wait = 0\n",
        "        self.early_stop = False\n",
        "        if self.mode == 'max':\n",
        "            self.best_score = float('-inf')\n",
        "        else:\n",
        "            self.best_score = float('inf')\n",
        "\n",
        "    def __call__(self, score, model=None):\n",
        "\n",
        "        if self.monitor_op(score, self.best_score):\n",
        "            # 有改善\n",
        "            self.best_score = score\n",
        "            self.wait = 0\n",
        "\n",
        "            # 保存最佳權重\n",
        "            if self.restore_best_weights and model is not None:\n",
        "                self.best_weights = {\n",
        "                    name: param.clone().detach()\n",
        "                    for name, param in model.named_parameters()\n",
        "                }\n",
        "        else:\n",
        "            # 沒有改善\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.stopped_epoch = self.wait\n",
        "                self.early_stop = True\n",
        "\n",
        "                # 恢復最佳權重\n",
        "                if self.restore_best_weights and model is not None and self.best_weights is not None:\n",
        "                    print(f\"恢復最佳權重（PSNR: {self.best_score:.2f}dB）\")\n",
        "                    for name, param in model.named_parameters():\n",
        "                        param.data.copy_(self.best_weights[name])\n",
        "\n",
        "        return self.early_stop\n",
        "\n",
        "    def get_status(self):\n",
        "\n",
        "        return {\n",
        "            'wait': self.wait,\n",
        "            'patience': self.patience,\n",
        "            'best_score': self.best_score,\n",
        "            'early_stop': self.early_stop\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "warmup_epochs = 0      # warmup 5 個 epochs\n",
        "total_epochs = 10      # 總共 50 個 epochs\n",
        "warmup_start_lr = 1e-6 # warmup 起始學習率\n",
        "base_lr = 1e-5         # 基礎學習率\n",
        "eta_min = 1e-6         # 最小學習率\n",
        "\n",
        "# 重新設置優化器的初始學習率\n",
        "for param_group in optimizer.param_groups:\n",
        "    param_group['lr'] = warmup_start_lr\n",
        "\n",
        "# 使用新的調度器\n",
        "scheduler = WarmupCosineAnnealingLR(\n",
        "    optimizer=optimizer,\n",
        "    warmup_epochs=warmup_epochs,\n",
        "    total_epochs=total_epochs,\n",
        "    warmup_start_lr=warmup_start_lr,\n",
        "    base_lr=base_lr,\n",
        "    eta_min=eta_min\n",
        ")\n",
        "\n",
        "print(f\"Warmup 調度器設置完成：\")\n",
        "print(f\"  Warmup epochs: {warmup_epochs}\")\n",
        "print(f\"  起始學習率: {warmup_start_lr:.2e}\")\n",
        "print(f\"  基礎學習率: {base_lr:.2e}\")\n",
        "print(f\"  最小學習率: {eta_min:.2e}\")\n",
        "print(f\"  當前學習率: {scheduler.get_lr():.2e}\")\n",
        "\n",
        "# 設置 Early Stopping\n",
        "patience = 10           # 等待改善的 epoch 數量\n",
        "min_delta = 0.01       # 最小改善幅度 (PSNR)\n",
        "early_stopping = EarlyStopping(\n",
        "    patience=patience,\n",
        "    min_delta=min_delta,\n",
        "    restore_best_weights=True,\n",
        "    mode='max'  # 監控 PSNR（越大越好）\n",
        ")\n",
        "\n",
        "print(f\"\\nEarly Stopping 設置完成：\")\n",
        "print(f\"  Patience: {patience} epochs\")\n",
        "print(f\"  最小改善幅度: {min_delta} dB\")\n",
        "print(f\"  監控指標: 驗證 PSNR (max mode)\")\n",
        "print(f\"  自動恢復最佳權重: 是\")"
      ],
      "metadata": {
        "id": "yoJi5v1w4WmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_lr_schedule():\n",
        "    \"\"\"視覺化學習率調度\"\"\"\n",
        "    epochs = list(range(1, 10))  # 顯示前20個epoch\n",
        "    lrs = []\n",
        "\n",
        "    for epoch in epochs:\n",
        "        if epoch <= warmup_epochs:\n",
        "            lr = warmup_start_lr + (base_lr - warmup_start_lr) * (epoch / warmup_epochs)\n",
        "        else:\n",
        "            cosine_epochs = total_epochs - warmup_epochs\n",
        "            current_cosine_epoch = epoch - warmup_epochs\n",
        "            lr = eta_min + (base_lr - eta_min) * (\n",
        "                1 + math.cos(math.pi * current_cosine_epoch / cosine_epochs)\n",
        "            ) / 2\n",
        "        lrs.append(lr)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(epochs, lrs, 'b-', linewidth=2, marker='o', markersize=4)\n",
        "    plt.axvline(x=warmup_epochs, color='red', linestyle='--', alpha=0.7,\n",
        "                label=f'Warmup 結束 (Epoch {warmup_epochs})')\n",
        "    plt.title('Warmup + Cosine Annealing 學習率調度')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Learning Rate')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.show()\n",
        "\n",
        "    print(\"前10個epoch的學習率變化：\")\n",
        "    for i, (epoch, lr) in enumerate(zip(epochs[:10], lrs[:10])):\n",
        "        status = \"Warmup\" if epoch <= warmup_epochs else \"Cosine\"\n",
        "        print(f\"  Epoch {epoch}: {lr:.2e} ({status})\")\n",
        "\n",
        "visualize_lr_schedule()"
      ],
      "metadata": {
        "id": "gErAFSTO4SAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%\n",
        "\n",
        "def train_epoch_stable(model, train_loader, criterion, optimizer, device, epoch, scaler=None):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_psnr = 0.0\n",
        "    num_batches = len(train_loader)\n",
        "\n",
        "    if scaler is None:\n",
        "        from torch.cuda.amp import GradScaler\n",
        "        scaler = GradScaler()\n",
        "\n",
        "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch}')\n",
        "\n",
        "    for batch_idx, batch in enumerate(progress_bar):\n",
        "        degraded = batch['degraded'].to(device, non_blocking=True)\n",
        "        clean = batch['clean'].to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            restored = model(degraded)\n",
        "            loss = criterion(restored, clean)\n",
        "\n",
        "            # 檢查loss是否異常\n",
        "            if torch.isnan(loss) or torch.isinf(loss) or loss.item() > 10.0:\n",
        "                print(f\"警告：檢測到異常loss值 {loss.item():.4f}，跳過此批次\")\n",
        "                continue\n",
        "\n",
        "        # 縮放損失並反向傳播\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        # 梯度裁剪 - 防止梯度爆炸\n",
        "        scaler.unscale_(optimizer)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            psnr = calculate_psnr(restored, clean)\n",
        "\n",
        "            # 檢查PSNR是否異常\n",
        "            if psnr < 0 or psnr > 100:\n",
        "                print(f\"警告：異常PSNR值 {psnr:.2f}dB\")\n",
        "                continue\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_psnr += psnr\n",
        "\n",
        "        progress_bar.set_postfix({\n",
        "            'Loss': f'{loss.item():.4f}',\n",
        "            'PSNR': f'{psnr:.2f}dB',\n",
        "            'Scale': f'{scaler.get_scale():.0f}'\n",
        "        })\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    avg_loss = total_loss / num_batches\n",
        "    avg_psnr = total_psnr / num_batches\n",
        "\n",
        "    return avg_loss, avg_psnr\n",
        "\n",
        "def validate(model, val_loader, criterion, device):\n",
        "    \"\"\"驗證函數\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_psnr = 0.0\n",
        "    num_batches = len(val_loader)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc='Validation'):\n",
        "            degraded = batch['degraded'].to(device)\n",
        "            clean = batch['clean'].to(device)\n",
        "\n",
        "            restored = model(degraded)\n",
        "            loss = criterion(restored, clean)\n",
        "            psnr = calculate_psnr(restored, clean)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            total_psnr += psnr\n",
        "\n",
        "    avg_loss = total_loss / num_batches\n",
        "    avg_psnr = total_psnr / num_batches\n",
        "\n",
        "    return avg_loss, avg_psnr\n"
      ],
      "metadata": {
        "id": "HjZU-2DSInXG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "# 將訓練集分割為訓練和驗證集 (80%-20%)\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_subset, val_subset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=10)\n",
        "val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=10)\n",
        "\n",
        "print(f'訓練集大小: {len(train_subset)}')\n",
        "print(f'驗證集大小: {len(val_subset)}')\n",
        "\n",
        "\n",
        "\n",
        "# 檢查是否有現有模型可以接續訓練\n",
        "# 接續訓練設置\n",
        "RESUME_TRAINING = True  # 設為 True 來啟用接續訓練\n",
        "MODEL_PATH = 'best_restormer_model.pth'\n",
        "\n",
        "# 初始化訓練參數\n",
        "num_epochs = 30\n",
        "start_epoch = 1\n",
        "best_psnr = 0.0\n",
        "train_losses = []\n",
        "train_psnrs = []\n",
        "val_losses = []\n",
        "val_psnrs = []\n",
        "\n",
        "# 嘗試載入現有模型\n",
        "if RESUME_TRAINING and os.path.exists(MODEL_PATH):\n",
        "    try:\n",
        "        print(f\"嘗試載入現有模型進行接續訓練...\")\n",
        "        checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
        "\n",
        "        # 載入模型權重\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "        # 載入優化器狀態（如果存在）\n",
        "        if 'optimizer_state_dict' in checkpoint:\n",
        "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            print(\"優化器狀態已載入\")\n",
        "\n",
        "        # 載入訓練進度\n",
        "        start_epoch = checkpoint.get('epoch', 1) + 1\n",
        "        best_psnr = checkpoint.get('best_psnr', 0.0)\n",
        "\n",
        "        # 載入歷史記錄（如果存在）\n",
        "        if 'train_losses' in checkpoint:\n",
        "            train_losses = checkpoint['train_losses']\n",
        "            train_psnrs = checkpoint['train_psnrs']\n",
        "            val_losses = checkpoint['val_losses']\n",
        "            val_psnrs = checkpoint['val_psnrs']\n",
        "            print(\"歷史記錄已載入\")\n",
        "\n",
        "        # 檢查是否是 early stopping 的模型\n",
        "        if checkpoint.get('early_stopped', False):\n",
        "            print(f\"  注意：這是一個 Early Stopping 的模型\")\n",
        "            print(f\"   原停止 epoch: {checkpoint.get('stopped_epoch', 'N/A')}\")\n",
        "\n",
        "            # 詢問是否要重置 early stopping\n",
        "            reset_early_stopping = input(\"是否重置 Early Stopping 狀態? (y/n): \").lower().strip()\n",
        "            if reset_early_stopping == 'y':\n",
        "                early_stopping.reset()\n",
        "                print(\" Early Stopping 狀態已重置\")\n",
        "            else:\n",
        "                print(\"  保持原有 Early Stopping 狀態\")\n",
        "\n",
        "        print(f\" 接續訓練設置完成:\")\n",
        "        print(f\"  - 起始 epoch: {start_epoch}\")\n",
        "        print(f\"  - 目標 epoch: {num_epochs}\")\n",
        "        print(f\"  - 當前最佳 PSNR: {best_psnr:.2f}dB\")\n",
        "        print(f\"  - 已有訓練記錄: {len(train_losses)} epochs\")\n",
        "\n",
        "        # 調整學習率調度器到正確的 epoch\n",
        "        for _ in range(start_epoch - 1):\n",
        "            scheduler.step()\n",
        "        print(f\"  - 當前學習率: {scheduler.get_lr():.6f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" 載入模型失敗: {e}\")\n",
        "        print(f\" 將從頭開始訓練\")\n",
        "        start_epoch = 1\n",
        "        best_psnr = 0.0\n",
        "        train_losses = []\n",
        "        train_psnrs = []\n",
        "        val_losses = []\n",
        "        val_psnrs = []\n",
        "\n",
        "else:\n",
        "    if RESUME_TRAINING:\n",
        "        print(f\"ℹ  未找到現有模型，將從頭開始訓練\")\n",
        "    else:\n",
        "        print(f\" 從頭開始訓練\")\n",
        "\n",
        "# 選擇訓練函數（推薦使用穩定版本）\n",
        "# train_epoch = train_epoch_gradient_clipped  # 更強的梯度裁剪版本\n",
        "train_epoch = train_epoch_stable              # 穩定版本，防止梯度爆炸\n",
        "\n",
        "print(f\"\\n開始訓練...\")\n",
        "print(f\"使用訓練函數: {train_epoch.__name__}\")\n",
        "if start_epoch > 1:\n",
        "    print(f\"接續從 Epoch {start_epoch} 開始\")\n",
        "\n",
        "# 訓練循環\n",
        "for epoch in range(start_epoch, num_epochs + 1):\n",
        "    print(f\"\\n=== Epoch {epoch}/{num_epochs} ===\")\n",
        "\n",
        "    # 訓練\n",
        "    train_loss, train_psnr = train_epoch_stable(model, train_loader, criterion, optimizer, device, epoch)\n",
        "\n",
        "    # 驗證\n",
        "    val_loss, val_psnr = validate(model, val_loader, criterion, device)\n",
        "\n",
        "    # 更新學習率\n",
        "    scheduler.step()\n",
        "\n",
        "    # 記錄結果\n",
        "    train_losses.append(train_loss)\n",
        "    train_psnrs.append(train_psnr)\n",
        "    val_losses.append(val_loss)\n",
        "    val_psnrs.append(val_psnr)\n",
        "\n",
        "    print(f'訓練 - Loss: {train_loss:.4f}, PSNR: {train_psnr:.2f}dB')\n",
        "    print(f'驗證 - Loss: {val_loss:.4f}, PSNR: {val_psnr:.2f}dB')\n",
        "\n",
        "    # 顯示學習率和 warmup 狀態\n",
        "    current_lr = scheduler.get_lr()\n",
        "    if epoch <= warmup_epochs:\n",
        "        warmup_progress = epoch / warmup_epochs * 100\n",
        "        print(f'學習率: {current_lr:.6f} (Warmup 階段: {warmup_progress:.1f}%)')\n",
        "    else:\n",
        "        print(f'學習率: {current_lr:.6f} (Cosine Annealing 階段)')\n",
        "\n",
        "    # 保存最佳模型（增強版 - 包含訓練歷史）\n",
        "    if val_psnr > best_psnr:\n",
        "        best_psnr = val_psnr\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.__dict__,  # 保存調度器狀態\n",
        "            'best_psnr': best_psnr,\n",
        "            'train_losses': train_losses,\n",
        "            'train_psnrs': train_psnrs,\n",
        "            'val_losses': val_losses,\n",
        "            'val_psnrs': val_psnrs,\n",
        "            'early_stopping_state': early_stopping.get_status(),\n",
        "            'resume_info': {\n",
        "                'total_epochs_trained': len(train_losses),\n",
        "                'original_start_epoch': start_epoch,\n",
        "                'training_resumed': start_epoch > 1\n",
        "            }\n",
        "        }, 'best_restormer_model.pth')\n",
        "        print(f\"新的最佳模型已保存！PSNR: {best_psnr:.2f}dB\")\n",
        "\n",
        "    # **Early Stopping 檢查**\n",
        "    if early_stopping(val_psnr, model):\n",
        "        # 取得 early stopping 狀態\n",
        "        status = early_stopping.get_status()\n",
        "        print(f\"\\n Early Stopping 觸發！\")\n",
        "        print(f\"  停止 epoch: {epoch}\")\n",
        "        print(f\"  最佳 PSNR: {status['best_score']:.2f}dB\")\n",
        "        print(f\"  已等待: {status['wait']}/{status['patience']} epochs\")\n",
        "        print(f\"  最佳權重已自動恢復\")\n",
        "\n",
        "        # 保存 early stopping 後的最終模型\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.__dict__,\n",
        "            'best_psnr': status['best_score'],\n",
        "            'early_stopped': True,\n",
        "            'stopped_epoch': epoch,\n",
        "            'train_losses': train_losses,\n",
        "            'train_psnrs': train_psnrs,\n",
        "            'val_losses': val_losses,\n",
        "            'val_psnrs': val_psnrs,\n",
        "            'early_stopping_state': status,\n",
        "            'resume_info': {\n",
        "                'total_epochs_trained': len(train_losses),\n",
        "                'original_start_epoch': start_epoch,\n",
        "                'training_resumed': start_epoch > 1\n",
        "            }\n",
        "        }, 'best_restormer_model.pth')\n",
        "\n",
        "        break\n",
        "\n",
        "    # 顯示 Early Stopping 狀態\n",
        "    status = early_stopping.get_status()\n",
        "    if status['wait'] > 0:\n",
        "        print(f\" Early Stopping: {status['wait']}/{patience} epochs (最佳 PSNR: {status['best_score']:.2f}dB)\")\n",
        "    else:\n",
        "        print(f\" 驗證指標改善！(目前最佳 PSNR: {status['best_score']:.2f}dB)\")\n",
        "\n",
        "# 訓練結束總結\n",
        "total_epochs_trained = len(train_losses)\n",
        "if early_stopping.early_stop:\n",
        "    print(f\"\\n 訓練因 Early Stopping 提前結束\")\n",
        "    print(f\"實際訓練 epochs: {epoch}\")\n",
        "    print(f\"最佳驗證 PSNR: {early_stopping.best_score:.2f}dB\")\n",
        "else:\n",
        "    print(f\"\\n 訓練正常完成\")\n",
        "    print(f\"總訓練 epochs: {num_epochs}\")\n",
        "    print(f\"最佳驗證 PSNR: {best_psnr:.2f}dB\")\n",
        "\n",
        "if start_epoch > 1:\n",
        "    print(f\" 接續訓練統計:\")\n",
        "    print(f\"  - 原有訓練: {start_epoch - 1} epochs\")\n",
        "    print(f\"  - 本次訓練: {total_epochs_trained - (start_epoch - 1)} epochs\")\n",
        "    print(f\"  - 總計訓練: {total_epochs_trained} epochs\")"
      ],
      "metadata": {
        "id": "oknJvHUwIncE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 繪製訓練曲線\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(train_losses, label='train loss')\n",
        "plt.plot(val_losses, label='val loss')\n",
        "# 如果有 early stopping，標記停止點\n",
        "if early_stopping.early_stop:\n",
        "    plt.axvline(x=len(train_losses), color='red', linestyle='--', alpha=0.7,\n",
        "                label=f'Early Stop (Epoch {len(train_losses)})')\n",
        "\n",
        "plt.title('train&val loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(train_psnrs, label='train PSNR')\n",
        "plt.plot(val_psnrs, label='val PSNR')\n",
        "# 如果有 early stopping，標記停止點\n",
        "if early_stopping.early_stop:\n",
        "    plt.axvline(x=len(train_losses), color='red', linestyle='--', alpha=0.7,\n",
        "                label=f'Early Stop (Epoch {len(train_losses)})')\n",
        "plt.title('train&val PSNR')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('PSNR (dB)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "# 計算實際的學習率變化曲線\n",
        "learning_rates = []\n",
        "actual_epochs = len(train_losses)  # 實際訓練的 epoch 數\n",
        "\n",
        "# 直接計算學習率，不使用 WarmupCosineAnnealingLR 類\n",
        "for epoch in range(1, actual_epochs + 1):\n",
        "    if epoch <= warmup_epochs:\n",
        "        # Warmup 階段\n",
        "        lr = warmup_start_lr + (base_lr - warmup_start_lr) * (epoch / warmup_epochs)\n",
        "    else:\n",
        "        # Cosine annealing 階段\n",
        "        cosine_epochs = total_epochs - warmup_epochs\n",
        "        current_cosine_epoch = epoch - warmup_epochs\n",
        "        lr = eta_min + (base_lr - eta_min) * (\n",
        "            1 + math.cos(math.pi * current_cosine_epoch / cosine_epochs)\n",
        "        ) / 2\n",
        "    learning_rates.append(lr)\n",
        "\n",
        "plt.plot(learning_rates, 'b-', linewidth=2)\n",
        "plt.axvline(x=warmup_epochs, color='red', linestyle='--', alpha=0.7,\n",
        "            label=f'Warmup 結束 (Epoch {warmup_epochs})')\n",
        "# 如果有 early stopping，標記停止點\n",
        "if early_stopping.early_stop:\n",
        "    plt.axvline(x=actual_epochs, color='orange', linestyle='--', alpha=0.7,\n",
        "                label=f'Early Stop (Epoch {actual_epochs})')\n",
        "plt.title('學習率變化 (Warmup + Cosine Annealing)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Learning Rate')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 顯示訓練統計信息\n",
        "print(f\"\\n 訓練統計信息：\")\n",
        "print(f\"  實際訓練 epochs: {actual_epochs}\")\n",
        "print(f\"  最佳驗證 PSNR: {max(val_psnrs):.2f}dB (Epoch {np.argmax(val_psnrs) + 1})\")\n",
        "print(f\"  最終驗證 PSNR: {val_psnrs[-1]:.2f}dB\")\n",
        "if early_stopping.early_stop:\n",
        "    print(f\"  Early Stopping: 是 (patience={patience})\")\n",
        "    print(f\"  最佳權重已恢復: 是\")\n",
        "else:\n",
        "    print(f\"  Early Stopping: 否\")"
      ],
      "metadata": {
        "id": "ygzdjVTnIomL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import torch\n",
        "\n",
        "MODEL_PATH = 'best_restormer_model.pth'\n",
        "\n",
        "if os.path.exists(MODEL_PATH):\n",
        "    print(f\" 找到已存在的模型: {MODEL_PATH}\")\n",
        "\n",
        "    try:\n",
        "        # 方法1: 嘗試使用 weights_only=False (適用於可信來源)\n",
        "        print(\" 嘗試載入完整檢查點...\")\n",
        "        checkpoint = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
        "\n",
        "        # 載入模型權重\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "        # 顯示模型信息\n",
        "        print(f\" 模型載入成功！\")\n",
        "        print(f\"  - 最佳 PSNR: {checkpoint.get('best_psnr', 'N/A'):.2f}dB\")\n",
        "        print(f\"  - 訓練 Epoch: {checkpoint.get('epoch', 'N/A')}\")\n",
        "\n",
        "        if checkpoint.get('early_stopped', False):\n",
        "            print(f\"  - Early Stopping: 是 (停止於 Epoch {checkpoint.get('stopped_epoch', 'N/A')})\")\n",
        "        else:\n",
        "            print(f\"  - Early Stopping: 否\")\n",
        "\n",
        "        # 檢查是否包含訓練歷史\n",
        "        if 'train_losses' in checkpoint:\n",
        "            print(f\"  - 訓練歷史: {len(checkpoint['train_losses'])} epochs\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" 載入失敗: {e}\")\n",
        "\n",
        "        # 方法2: 嘗試只載入模型權重\n",
        "        try:\n",
        "            print(\" 嘗試只載入模型權重...\")\n",
        "            # 使用 weights_only=True 只載入權重\n",
        "            state_dict = torch.load(MODEL_PATH, map_location=device, weights_only=True)\n",
        "\n",
        "            # 如果直接是 state_dict\n",
        "            if 'model_state_dict' in state_dict:\n",
        "                model.load_state_dict(state_dict['model_state_dict'])\n",
        "            else:\n",
        "                model.load_state_dict(state_dict)\n",
        "\n",
        "            print(\" 模型權重載入成功！\")\n",
        "            print(\"  注意：只載入了模型權重，無法獲取訓練歷史信息\")\n",
        "\n",
        "        except Exception as e2:\n",
        "            print(f\" 權重載入也失敗: {e2}\")\n",
        "            print(\" 將使用新初始化的模型\")\n",
        "\n",
        "else:\n",
        "    print(f\"ℹ  未找到模型檔案: {MODEL_PATH}\")\n",
        "    print(\" 將使用新初始化的模型\")\n",
        "\n",
        "print(\"\\n模型準備完成，可以開始推論或繼續訓練\")\n",
        "\n",
        "def test_and_save_results(model, test_loader, device, save_path='pred.npz'):\n",
        "    \"\"\"測試模型並保存結果為 npz 格式\"\"\"\n",
        "    model.eval()\n",
        "    results = {}\n",
        "\n",
        "    print(\"開始測試...\")\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, desc='Testing'):\n",
        "            degraded = batch['degraded'].to(device)\n",
        "            filename = batch['filename'][0]  # batch_size=1 for test\n",
        "\n",
        "            # 模型推理\n",
        "            restored = model(degraded)\n",
        "\n",
        "            # 轉換為 numpy 陣列\n",
        "            restored_np = restored.cpu().squeeze(0).numpy()  # (3, H, W)\n",
        "\n",
        "            # 確保值在 [0, 1] 範圍內\n",
        "            restored_np = np.clip(restored_np, 0, 1)\n",
        "\n",
        "            # 轉換為 uint8 格式 (0-255)\n",
        "            restored_np = (restored_np * 255).astype(np.uint8)\n",
        "\n",
        "            # 使用原始檔名作為鍵值\n",
        "            results[filename] = restored_np\n",
        "\n",
        "    # 保存結果\n",
        "    np.savez_compressed(save_path, **results)\n",
        "    print(f\"測試結果已保存到 {save_path}\")\n",
        "    print(f\"共處理 {len(results)} 張圖像\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# 執行測試並生成結果\n",
        "if MODEL_LOADED:\n",
        "    print(f\" 使用已載入的預訓練模型進行測試\")\n",
        "else:\n",
        "    print(f\" 使用當前模型進行測試\")\n",
        "\n",
        "test_results = test_and_save_results(model, test_loader, device, 'pred.npz')\n",
        "\n",
        "# 顯示一些測試結果\n",
        "def show_test_samples(results, test_dataset, num_samples=4):\n",
        "    \"\"\"顯示測試樣本\"\"\"\n",
        "    sample_keys = list(results.keys())[:num_samples]\n",
        "\n",
        "    if len(sample_keys) == 0:\n",
        "        print(\" 沒有測試結果可以顯示\")\n",
        "        return\n",
        "\n",
        "    # 處理單張圖像的情況\n",
        "    if len(sample_keys) == 1:\n",
        "        num_samples = 1\n",
        "        fig, axes = plt.subplots(2, 1, figsize=(8, 8))\n",
        "        axes = axes.reshape(2, 1)\n",
        "    else:\n",
        "        num_samples = min(num_samples, len(sample_keys))\n",
        "        fig, axes = plt.subplots(2, num_samples, figsize=(4*num_samples, 8))\n",
        "        if num_samples == 1:\n",
        "            axes = axes.reshape(2, 1)\n",
        "\n",
        "    for i, key in enumerate(sample_keys[:num_samples]):\n",
        "        # 載入原始降質圖像\n",
        "        degraded = None\n",
        "        for batch in test_loader:\n",
        "            if batch['filename'][0] == key:\n",
        "                degraded = batch['degraded'].squeeze(0).numpy()\n",
        "                break\n",
        "\n",
        "        if degraded is None:\n",
        "            print(f\"  無法找到原始圖像: {key}\")\n",
        "            continue\n",
        "\n",
        "        # 取得修復後的圖像\n",
        "        restored = results[key] / 255.0  # 轉回 [0,1] 範圍\n",
        "\n",
        "        # 顯示降質圖像\n",
        "        axes[0, i].imshow(np.transpose(degraded, (1, 2, 0)))\n",
        "        axes[0, i].set_title(f'降質圖像: {key}')\n",
        "        axes[0, i].axis('off')\n",
        "\n",
        "        # 顯示修復圖像\n",
        "        axes[1, i].imshow(np.transpose(restored, (1, 2, 0)))\n",
        "        axes[1, i].set_title(f'修復圖像: {key}')\n",
        "        axes[1, i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "show_test_samples(test_results, test_dataset)\n",
        "\n",
        "# 顯示最終狀態\n",
        "print(f\"\\n 測試完成總結:\")\n",
        "print(f\"  - 使用模型: {'預訓練模型' if MODEL_LOADED else '當前模型'}\")\n",
        "print(f\"  - 測試圖像數量: {len(test_results)}\")\n",
        "print(f\"  - 輸出檔案: pred.npz\")"
      ],
      "metadata": {
        "id": "lrcj3bBzJk1o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}